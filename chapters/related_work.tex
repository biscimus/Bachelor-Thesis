\begin{comment}
    In this section, you are going to list all the related work.
In this template, the related work section is located directly after the introduction chapter, however, this is not always the best/most logical location.
As a general guideline, the position of the related work section can be:
\begin{itemize}
    \item \emph{Directly after the introduction}; Position the related work section here, in case you do not need to refer to any detailed (mathematical) concepts.
    Furthermore, you do not need to refer to any part of your solution. 
    Positioning the related work section here is most commonly done if you are really uncovering ``new terrain'', i.e., you are doing something \emph{very novel}.
    \item \emph{Directly after preliminaries}; In this scenario, you swap the related work and preliminaries, i.e., w.r.t. this thesis template.
    Position this here when you do need to refer to some of the (mathematical) concepts (typically presented in the preliminaries), yet, you do not need to use any properties of your own solution when comparing your work to the related literature.
    \item \emph{Directly before the Conclusion (typically after the Evaluation)}; Position the related work section here, in case you need to compare the related work against properties of your algorithm and/or the results you have obtained.
\end{itemize}

In some cases, you can introduce sub-sections in this chapter, i.e., if a division of the related work eases the readability.

Note that the related work is not intended for you to \enquote{Convince your supervisors that you have studied a lot of papers}.
Rather, you simply describe in 1, max 2 lines what the core idea of a paper is, how it relates to your work and why it is different from your work.
In some cases, it is possible to discuss the aforementioned points for a selection of papers rather than a single paper.
Try to present the paper along logical lines, i.e., define categories of work and introduce subsections for this.
Never present a long 2-page list of randomly/chronologically structured work.
Always add a decent structure!
\end{comment}

\section{Data-Aware Process Mining}

Conventional process discovery algorithms only consider the control-flow aspect of the process, i.e. the activity attribute of the event log, thereby ignoring the data attributes the event log provides. Data-aware process mining, on the other hand, attempts to incorporate both the control-flow and data attributes of the event log. The prevalent repretoire is to discover decision points in the model and to annotate them with guard functions, which in turn are discovered with decision trees. This method of process enhancement is called \emph{decision mining} \cite{decision-mining-in-prom,decision-mining-in-business-processes,data-aware-process-mining}, and is a well-estalished field of research within process mining. De Leoni et al. \cite{data-aware-process-mining} proposes a Petri net with data \emph{(DPN-net)} setting to expand the notation of Petri nets. While previous papers worked with the assumption of deterministic, mutual exclusive transition behavior in decision points, they do not take into account how certain decisions cannot be modeled dichotomously. Often, one needs a softer classification assumption, stating that data attributes affect the decision probabilistically. Mannhardt et al. \cite{sldpn} further extends the concept of data-annotated Petri nets by integrating stochastic information into the model. In the paper, the authors introduce the concept of stochastic labeled data Petri nets \emph{SLDPNs} and propose a method to generate an SLDPN from a Petri net and an event log. Each transition will be mapped with its own weight function learned with the activiation instances of individual transitions using logistic regression.

\section{Translucent Event Logs}

Little research has been performed on the topic of translucent event logs. Being a relatively young concept in the field of process mining, they were first hinted in 2018 by van der Aalst \cite{lucency-first-paper}, where a possible event log revealing the set of enabled activities is mentioned. \cite{Translucent-event-logs-first-paper} formally introduces and defines translucent event logs and relates concepts of lucency and translucency by showing that a lucent process model can be rediscovered by using a translucent event log retrieved from the model. Methods of creating translucent event logs are first discussed in Bayel et al. \cite{creating-translucent-event-logs}. Here, a system's screenshot is matched with the labelled activity pattern and annotated with the corresponding activities. Furthermore, a model-based approach is introduced by replaying the event log on the model and annotating enabled activities. \cite{translucent-precision} formally introduces a precision measure between a Petri net and a translucent event log by comparing log-enabled activities and model-enabled activities.

\section{Predictive Process Monitoring}


\begin{itemize}
    \item Explain the term and list previous differnet approaches
    \item Lin et al. \cite{predictive-process-monitoring-rnn}: Next event and next data attribute prediction using RNNs
    \item Gunnarsson et al. \cite{predictive-process-monitoring-lstm}: Remaining trace and runtime prediction using LSTMs
    \item Bukhsh et al. \cite{predictive-process-monitoring-transformer}: Next activity, next event time, and remaining time prediction using transformer architecture
    \item General overview of the field is given in \cite{predictive-process-monitoring}.
\end{itemize}